{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer-based Text Representation\n",
    "\n",
    "Transformer-based Text Representation refers to word or sentence embeddings generated by models that use the self-attention mechanism to convert text data into vectors (numerical representations). This approach has gained popularity, especially with models like BERT, GPT, T5, RoBERTa, and XLNet.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- #### Multi-Head Attention:\n",
    "\n",
    "  Multi-Head Attention is a structure that runs multiple self-attention mechanisms in parallel.\n",
    "\n",
    "  - Features:\n",
    "\n",
    "    - Captures different contexts &rarr; Different heads allow the model to learn word relationships from various perspectives.\n",
    "    - Runs in parallel &rarr; Multiple self-attention computations are performed and the results are combined.\n",
    "    - Prevents information loss &rarr; Instead of using a single attention mechanism, multiple heads enrich the information.\n",
    "      <br>\n",
    "      <br>\n",
    "\n",
    "- #### Masked Multi-Head Attention:\n",
    "\n",
    "  Masked Multi-Head Attention works by masking future words.\n",
    "  It is commonly used in language model training (such as GPT) and seq2seq models (e.g., chatbots, machine translation).\n",
    "\n",
    "  - Whatâ€™s the difference?\n",
    "\n",
    "    - Normal Self-Attention &rarr; Considers all words.\n",
    "    - Masked Self-Attention &rarr; Considers only previous words and \"masks\" the future words to predict them.\n",
    "      <br>\n",
    "      <br>\n",
    "\n",
    "- #### Add & Norm (Addition and Normalization):\n",
    "\n",
    "  - These are two critical components used in each transformer block:\n",
    "\n",
    "    - Residual Connection (Add) &rarr; Combines the input and output to prevent information loss.\n",
    "    - Layer Normalization (Norm) &rarr; Stabilizes the model's training process.\n",
    "      <br>\n",
    "      <br>\n",
    "\n",
    "- #### Feed Forward Network (FFN):\n",
    "\n",
    "  After each attention layer, a fully connected neural network (MLP) follows in a transformer.\n",
    "  <br>\n",
    "  <br>\n",
    "\n",
    "- #### Input & Output Embeddings:\n",
    "\n",
    "  Transformers process words by converting them into vectors.\n",
    "\n",
    "  - Input Embedding:\n",
    "\n",
    "    - Each word is converted into a fixed-length vector.\n",
    "    - These vectors are created using word embeddings, which carry the contextual meaning of the words.\n",
    "    - Example: \"hello\" &rarr; [0.12, 0.85, -0.45, ...]\n",
    "      <br>\n",
    "      <br>\n",
    "\n",
    "- #### Linear (Fully Connected Layer):\n",
    "\n",
    "  This is the final layer of the transformer, which processes the output for word prediction.\n",
    "  <br>\n",
    "  <br>\n",
    "\n",
    "- #### Softmax (Probability Distribution)\n",
    "\n",
    "  Softmax converts the output into a probability distribution and selects the most likely word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Representation (First token):\n",
      " [-1.35336190e-01 -1.13854200e-01 -1.07623339e-01  1.60552442e-01\n",
      " -4.46132481e-01 -3.62620324e-01  2.91389942e-01  6.56760871e-01\n",
      "  1.24576457e-01 -2.41161659e-01  1.84239879e-01  9.58727002e-02\n",
      "  4.85659018e-02  9.06549916e-02  1.08772933e-01 -5.23374006e-02\n",
      " -2.53350526e-01  6.48282230e-01  2.65885174e-01  1.44905701e-01\n",
      " -1.14159741e-01 -3.58102292e-01  3.82253021e-01 -2.88915988e-02\n",
      "  6.59064576e-02 -3.52836013e-01  1.00523211e-01 -2.54869074e-01\n",
      " -2.54663825e-01  1.89151853e-01 -3.58156115e-01  4.04400676e-01\n",
      " -2.78848946e-01 -4.03717488e-01  4.03150648e-01 -6.64508194e-02\n",
      "  1.25667036e-01 -1.86263055e-01  1.02758877e-01 -1.58098474e-01\n",
      " -2.72423059e-01 -2.71067470e-02  1.15523800e-01 -1.35344446e-01\n",
      " -6.70103788e-01 -1.70308184e-02 -3.22344208e+00 -8.86515826e-02\n",
      " -3.37871909e-01 -3.52163702e-01  2.26560056e-01 -2.31863350e-01\n",
      "  6.39325604e-02  3.76260191e-01 -7.27623701e-02  1.21075355e-01\n",
      " -2.58751571e-01  3.81401926e-01  8.95989016e-02  1.41537145e-01\n",
      "  1.33061595e-02  2.58200645e-01 -3.31671953e-01 -1.36795327e-01\n",
      " -1.19551666e-01  4.95919697e-02  9.79594812e-02  2.76531987e-02\n",
      " -4.22024250e-01  3.72941047e-01 -4.33175892e-01 -2.48264879e-01\n",
      "  2.81549662e-01 -1.17005005e-01 -1.87466592e-01  5.85932285e-03\n",
      " -7.28890374e-02  2.50838876e-01 -1.88999444e-01  6.67047203e-02\n",
      "  2.57917531e-02  7.49035001e-01  3.22066516e-01 -2.93613434e-01\n",
      " -1.17645033e-01  8.02275658e-01 -6.72158003e-02 -3.15026611e-01\n",
      "  2.16604352e-01  1.01395786e-01 -3.33885491e-01 -2.37560928e-01\n",
      "  9.74716246e-02  5.69991052e-01  3.29016268e-01 -5.44423833e-02\n",
      " -1.25333875e-01 -2.21343517e-01  3.16277072e-02  4.95915413e-01\n",
      "  2.62192219e-01 -1.07689254e-01  2.68694222e-01 -5.49066067e-01\n",
      "  1.82150543e-01 -2.21044078e-01 -2.00108916e-01 -2.00924799e-01\n",
      "  1.04111195e-01 -2.68254828e+00  2.94796139e-01 -5.11682406e-03\n",
      " -2.45987669e-01 -4.11434084e-01 -3.68279189e-01  6.18665636e-01\n",
      "  4.20049906e-01  4.41232622e-02  4.41953540e-01  1.36133552e-01\n",
      "  3.41539741e-01  6.71562493e-01 -1.33643404e-01  9.18150544e-02\n",
      " -2.21375316e-01 -1.00849852e-01  1.19643524e-01  8.98139626e-02\n",
      "  4.11897987e-01  1.20511740e-01  2.80230165e-01  6.78202510e-01\n",
      "  1.86194554e-01 -5.28249815e-02  1.45638391e-01 -3.17384824e-02\n",
      "  3.51425171e-01 -2.04190895e-01 -4.15910333e-01 -1.26801610e-01\n",
      " -3.61295253e-01  8.90751779e-02 -3.00070810e+00 -4.84377071e-02\n",
      "  3.58477354e-01 -6.11695424e-02 -3.74478549e-01 -5.98245412e-02\n",
      " -1.33340694e-02  3.06924790e-01  1.23340182e-01  1.25081643e-01\n",
      " -1.92648694e-01 -1.08755097e-01  3.88595648e-02 -4.09666896e-02\n",
      " -6.02162071e-02 -4.20814633e-01  5.14853656e-01  2.54381150e-01\n",
      " -6.55948520e-01 -3.39538842e-01 -1.42200127e-01 -3.47857386e-01\n",
      " -3.89244556e-01  4.97322828e-02  6.96135163e-01  2.34165579e-01\n",
      " -3.71328443e-02 -7.92649910e-02  1.61860123e-01  1.77917585e-01\n",
      "  2.72168964e-01  3.21033318e-03  2.25934014e-01 -5.28682232e-01\n",
      "  6.21289015e-04  2.25456446e-01  1.57541111e-01  1.59309596e-01\n",
      " -3.53104174e-01  6.32717371e-01  3.58103275e-01  1.76484883e-02\n",
      "  5.11642635e-01 -1.34096786e-01  3.41489851e-01 -2.89667070e-01\n",
      " -4.52598780e-01 -1.03090080e-02 -2.98431143e-03 -3.05813670e-01\n",
      "  2.33552679e-01  1.02951810e-01  6.17456675e-01  1.56292558e-01\n",
      "  3.06437135e-01 -2.88997203e-01  1.67543069e-01  3.84569496e-01\n",
      " -1.67049050e-01 -6.68582171e-02  1.74305402e-02 -5.72745539e-02\n",
      " -1.13301411e-01  3.98567224e+00 -1.03827506e-01  2.20872328e-01\n",
      "  3.34887244e-02 -1.44530535e-01 -1.53991347e-02 -2.70120025e-01\n",
      " -1.13856912e-01 -2.88722664e-01 -1.75132588e-01  7.72878230e-02\n",
      "  3.47723901e-01 -1.83924213e-02  8.11901838e-02 -2.35030949e-01\n",
      "  3.42334151e-01  3.02732617e-01 -8.77878964e-02  2.66363084e-01\n",
      " -4.42229033e-01  1.21380515e-01 -1.38239563e-02  5.00451088e-01\n",
      "  9.12383497e-02 -1.27035487e+00 -1.87132537e-01 -3.43878627e-01\n",
      " -5.45015275e-01  1.36713713e-01 -1.37648329e-01 -3.42850298e-01\n",
      " -2.95150876e-02 -2.20200837e-01  2.71710604e-01 -8.59522074e-02\n",
      " -2.29688615e-01  2.73917437e-01 -2.35058874e-01  1.78164661e-01\n",
      "  1.06258407e-01 -3.31184603e-02  2.01057747e-01 -3.13556075e-01\n",
      "  4.76182550e-01 -3.83595586e-01  3.54673803e-01  2.11092681e-01\n",
      "  2.44994029e-01 -1.37171045e-01  4.24194962e-01  1.78866982e-01\n",
      "  8.81519169e-04  9.99799892e-02 -4.59335633e-02 -1.72060579e-01\n",
      " -3.29764187e-02  9.38098505e-03 -2.03474760e-02 -6.08141869e-02\n",
      " -5.39952159e-01 -4.87006217e-01  2.03482911e-01 -2.72754192e-01\n",
      "  2.55070150e-01 -3.60060394e-01 -7.05031604e-02 -2.24871844e-01\n",
      " -1.67251915e-01 -3.83781195e+00 -2.04059914e-01 -2.94910669e-01\n",
      "  2.16799974e-01  2.06619520e-02 -4.00844187e-01 -1.36676446e-01\n",
      "  3.06983173e-01  3.84246320e-01 -1.36843443e-01  3.11579317e-01\n",
      "  1.00146368e-01 -1.61680698e-01  3.27903777e-01 -2.41607532e-01\n",
      "  2.82685667e-01 -2.08294764e-02 -4.19064909e-01 -5.21288931e-01\n",
      " -1.04013123e-01  2.83390693e-02 -9.00959522e-02 -8.12608674e-02\n",
      "  4.39725757e-01 -1.37544200e-01 -3.33793879e-01 -1.26304984e-01\n",
      " -3.66567850e-01 -1.00667700e-02 -3.98259312e-02  1.18186921e-02\n",
      " -3.91679794e-01 -1.89935505e-01  2.14980133e-02  1.04396746e-01\n",
      " -2.60069203e+00  2.86166400e-01 -4.51826930e-01  6.75767194e-03\n",
      "  1.43046036e-01 -1.08357957e-02  3.60682011e-01 -3.40033650e-01\n",
      " -4.49274689e-01  2.44236991e-01  4.15435493e-01  2.15521038e-01\n",
      " -4.19641174e-02  8.44079852e-02  2.77248800e-01  2.19219774e-01\n",
      "  3.84776384e-01 -2.70615458e-01  3.14129323e-01  3.17703366e-01\n",
      " -1.81743726e-02  5.87273240e-02 -2.58805789e-03 -1.43517897e-01\n",
      "  3.93501341e-01  3.72904658e-01 -7.27834523e-01 -1.13341160e-01\n",
      " -1.54470086e-01 -1.44114941e-01 -1.22226566e-01 -1.76146030e-02\n",
      "  2.66811520e-01 -3.08162212e-01 -5.08330822e-01 -3.73677075e-01\n",
      "  3.37097466e-01  3.25623959e-01  4.82677996e-01 -1.19069487e-01\n",
      "  1.41986907e-01  6.93219125e-01 -1.26391038e-01  1.74651831e-01\n",
      "  1.59263641e-01  7.02571273e-02  7.07956403e-02  6.48999438e-02\n",
      "  2.16980428e-01  1.74269557e-01 -1.03043243e-01  9.74651203e-02\n",
      "  1.40035892e+00  4.44161326e-01 -1.23606145e-01 -2.43746459e-01\n",
      "  4.29895997e-01  1.88150838e-01  2.90182263e-01  1.78639323e-01\n",
      "  7.19702780e-01 -5.73098361e-01  3.69889826e-01 -5.67590117e-01\n",
      " -9.16058570e-03 -4.95924294e-01  1.29009798e-01 -4.14020061e-01\n",
      " -3.21132764e-02  4.71505895e-02  3.31115946e-02  7.34219491e-01\n",
      " -5.12380421e-01 -1.10363948e+00  6.98945113e-03  1.04930289e-02\n",
      " -3.55977505e-01 -1.11260973e-01  2.04883963e-01  5.05260527e-01\n",
      " -3.31648260e-01  2.57879794e-02 -6.10345364e-01  2.37089843e-01\n",
      " -1.43825293e-01 -3.45436454e-01 -2.17415869e-01  3.72669511e-02\n",
      " -3.38516116e-01 -1.74067825e-01 -7.99782500e-02  6.36058971e-02\n",
      "  2.73277730e-01  8.60397816e-02  5.01928292e-02 -4.11824137e-03\n",
      "  4.80143651e-02 -6.50310993e-01  3.68612260e-03 -3.25394630e-01\n",
      " -4.35890287e-01  2.17328556e-02 -3.91631663e-01  1.44890279e-01\n",
      " -7.45842531e-02 -1.47799194e-01 -4.62062955e-01  1.08414814e-01\n",
      "  1.11615747e-01 -1.68281347e-02 -2.35613957e-01  2.74096578e-01\n",
      "  2.24141330e-01  2.79396653e-01  8.06720316e-01 -8.50491673e-02\n",
      "  2.70620972e-01  4.93116319e-01  1.29152596e-01 -1.11157186e-01\n",
      "  1.81382984e-01  2.32585892e-01 -2.52164066e-01  2.02311233e-01\n",
      " -1.55897394e-01 -7.75629431e-02  1.73152655e-01  2.13888913e-01\n",
      " -5.95627248e-01 -3.67024601e-01  5.97186200e-02 -3.00283015e-01\n",
      " -4.47440594e-01 -2.96813786e-01 -3.85153651e-01 -3.30848157e-01\n",
      " -1.20045930e-01  4.51520741e-01  1.63337708e-01 -1.10176452e-01\n",
      "  4.05127108e-01 -7.95967132e-02 -1.65780932e-01  2.86170542e-01\n",
      "  2.88838536e-01  3.63715410e-01  1.42688081e-01  2.23659784e-01\n",
      " -2.89620876e-01  4.78958845e-01  2.85932273e-01 -7.24834725e-02\n",
      "  3.88442725e-02 -4.53717440e-01  5.98390162e-01  2.32234329e-01\n",
      "  8.09893459e-02 -4.92868423e-02  1.41284630e-01 -1.46808416e-01\n",
      "  5.97737074e-01  3.07337135e-01 -1.57832992e+00  1.47914916e-01\n",
      "  7.20944762e-01 -2.58415014e-01  2.95760900e-01 -3.20192754e-01\n",
      " -5.04801810e-01  5.95685899e-01  1.99565127e-01  1.56498760e-01\n",
      " -5.27371228e-01 -1.89810783e-01  2.08509155e-04 -1.12382069e-01\n",
      "  3.64928722e-01  1.15081249e-02 -5.53959832e-02 -3.35722357e-01\n",
      "  2.55042732e-01 -1.94342792e-01  8.63214489e-04  1.69056147e-01\n",
      " -2.12097421e-01  4.57225181e-02 -1.91388540e-02 -1.79580614e-01\n",
      " -4.62847561e-01  1.87066466e-01  1.72766268e-01  4.80233818e-01\n",
      "  1.16587758e-01 -3.78656715e-01 -6.77570343e-01 -1.17185988e-01\n",
      "  5.87147593e-01 -3.16043973e-01 -8.53077695e-02 -2.78107107e-01\n",
      "  5.66237926e-01  3.85705411e-01 -4.88257051e-01  3.21795821e-01\n",
      "  4.58403409e-01  1.18915386e-01  9.93749574e-02  2.26287588e-01\n",
      " -1.50263757e-01  5.23967385e-01 -1.23007745e-01 -4.17667300e-01\n",
      " -1.78425744e-01 -3.80887836e-01 -9.66500193e-02  8.08238983e-02\n",
      "  2.48789310e-01  4.45937663e-02 -2.42868677e-01  1.06217533e-01\n",
      " -6.75279915e-01 -1.52375996e-01  5.35595119e-02 -5.14343262e-01\n",
      " -3.39289159e-01  4.01966870e-02 -4.70863491e-01 -7.39776015e-01\n",
      " -2.59105489e-02 -4.64940995e-01 -3.57594937e-01  2.48527646e-01\n",
      "  6.66336536e-01  3.68418008e-01 -3.71137798e-01  6.70892119e-01\n",
      "  3.53125297e-02  3.22515011e-01  2.06616744e-02 -8.30053166e-02\n",
      "  4.17949498e-01 -2.74814278e-01 -3.35145593e-01 -1.30257994e-01\n",
      "  9.95146260e-02  4.75028813e-01  1.10043129e-02  3.14703546e-02\n",
      " -2.25453764e-01 -1.77999049e-01 -1.30452365e-01 -6.73209727e-02\n",
      " -2.75769770e-01 -5.73899209e-01  5.68700790e-01  9.74043906e-02\n",
      "  2.30090216e-01  9.42011178e-03  1.30258590e-01 -9.89697874e-02\n",
      "  1.67427272e-01 -1.74619347e-01 -4.55727667e-01  4.36674386e-01\n",
      "  2.39032656e-01  2.08766282e-01 -9.27828252e-03  1.91961423e-01\n",
      "  6.81773722e-01  5.17728567e-01 -3.11185926e-01 -2.13616282e-01\n",
      "  2.76568621e-01  1.45376801e-01  5.67071512e-03 -1.15859389e-01\n",
      "  4.40723002e-01 -3.98463666e-01  3.70778292e-01 -4.84863251e-01\n",
      "  2.60883093e+00  1.65960044e-01  4.91045266e-01 -7.38906264e-01\n",
      "  2.16405809e-01 -1.35270715e-01 -2.88764834e-01  2.02036291e-01\n",
      " -2.12479770e-01  4.43066537e-01 -2.13814408e-01  3.17673296e-01\n",
      " -2.07083121e-01  2.48242766e-01  2.31188461e-01  2.09501326e-01\n",
      " -1.62439972e-01 -1.91265836e-01 -7.48872399e-01 -1.27790302e-01\n",
      " -3.41603041e-01  7.21512139e-01  3.01245034e-01 -4.36881781e-02\n",
      "  2.59324700e-01  3.47141087e-01  7.14450516e-03  2.49795675e-01\n",
      "  1.55693322e-01 -4.35903668e-02 -2.53936172e-01  3.28105956e-01\n",
      "  1.91877171e-01  4.06475961e-01 -1.96699932e-01  1.31099001e-01\n",
      "  3.15282464e-01 -2.66613245e-01 -3.28309089e-01  1.21391892e-01\n",
      "  2.00670764e-01 -6.73090398e-01  6.82141900e-01  8.87270421e-02\n",
      " -3.42613220e-01  7.30960965e-01  7.17660263e-02 -5.79956651e-01\n",
      "  3.60857844e-01  3.94048125e-01  5.44847697e-02  6.88226581e-01\n",
      " -3.20829958e-01 -8.67797956e-02 -2.15062033e-03 -3.39134365e-01\n",
      "  3.58806625e-02  2.38487162e-02 -4.47955169e-02  3.60417008e-01\n",
      " -6.42598867e-02  2.57196724e-01  1.69613570e-01 -4.34280753e-01\n",
      " -2.58112937e-01  2.01637849e-01 -2.01876938e-01  6.84960246e-01\n",
      "  2.80197114e-01 -1.99256569e-01  7.00074360e-02  5.95744491e-01\n",
      "  2.11981863e-01  5.02236247e-01  3.57622147e-01 -3.04206870e-02\n",
      "  3.60067546e-01  1.44328233e-02  2.22501829e-02 -2.87105155e+00\n",
      "  1.28538802e-01  5.67795515e-01  3.98610324e-01 -2.31274981e-02\n",
      "  4.00321633e-01  5.34824431e-01 -3.56250912e-01  4.20473777e-02\n",
      " -2.35366270e-01  1.87614426e-01  3.81528467e-01  7.03921974e-01\n",
      "  1.71700880e-01  2.02282920e-01  2.44604379e-01  1.49769532e-02\n",
      " -4.56106126e-01  1.13984697e-01 -2.33931899e-01  2.39746034e-01\n",
      " -4.11803126e-02  2.10760713e-01 -2.50608385e-01 -4.41028297e-01\n",
      "  3.50735009e-01  2.39938766e-01 -9.42031443e-02 -1.06814206e-02\n",
      "  6.03729129e-01 -9.23685431e-02  2.15435356e-01 -1.24206766e-01\n",
      "  1.26280963e-01  1.30098075e-01  1.03142120e-01 -1.53312325e-01\n",
      "  7.16355890e-02  1.57074824e-01 -1.22972302e-01 -2.26442963e-02\n",
      "  6.23751760e-01 -1.02146357e-01  5.40234149e-01 -9.89416540e-02\n",
      " -3.00996423e-01  4.75602746e-01 -1.89185843e-01  5.56121171e-01\n",
      " -4.17245716e-01 -6.68027475e-02  2.19526991e-01  1.42260149e-01\n",
      "  1.80511445e-01  2.50558883e-01  1.46270901e-01  2.65126288e-01\n",
      " -7.37886280e-02 -7.86626637e-02 -1.69568568e-01 -2.12663531e-01\n",
      "  1.39517158e-01 -2.73522764e-01 -2.07493186e-01 -2.75707245e-03\n",
      " -2.56341338e-01 -1.45965412e-01  1.05802305e-01 -1.09330446e-01\n",
      " -5.61746299e-01 -2.66582936e-01  5.44421896e-02  7.09837019e-01\n",
      "  1.49268731e-01  1.64278239e-01  1.35681823e-01  2.33665407e-01\n",
      " -4.16988432e-02  1.89872995e-01 -8.41544569e-02 -3.29865813e-02\n",
      " -2.44687200e-02 -2.70677179e-01  1.59752160e-01  1.56897500e-01\n",
      " -7.81568480e+00 -2.71804214e-01 -2.95152366e-01 -7.18276083e-01\n",
      "  3.33649144e-02 -6.30518317e-01  3.55314612e-02 -2.01131493e-01\n",
      "  1.61116898e-01 -4.55872640e-02  6.62964806e-02  4.06927198e-01\n",
      " -2.31885118e-03 -5.07426143e-01  1.30481780e-01  5.35678864e-01]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Model and Tokenizer implement\n",
    "model_name = \"bert-base-uncased\"  # lower/upper uncased\n",
    "model = AutoModel.from_pretrained(model_name)  # pre implemented model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)  # tokenizer for model\n",
    "\n",
    "# Text\n",
    "text = \"Transformers are amazing for natural language processing.\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Text representation\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Output\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "first_token_embedding = last_hidden_state[\n",
    "    0, 0, :\n",
    "].numpy()  # [batch, token (Transformers word of text), vector]\n",
    "\n",
    "print(\"Text Representation (First token):\\n\", first_token_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
