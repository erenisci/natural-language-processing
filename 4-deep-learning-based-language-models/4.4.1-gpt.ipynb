{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT (Generative Pretrained Transformer)\n",
    "\n",
    "**GPT** is a language model developed by OpenAI that utilizes the transformer architecture for generating coherent and meaningful text. It is primarily designed to generate text based on a given input prompt, and it has been widely used for various applications like text completion, dialogue systems, and content generation.\n",
    "\n",
    "#### GPT Architecture\n",
    "\n",
    "- GPT is based on the **Transformer** architecture, specifically using only the **Decoder** part of the Transformer. Unlike models like BERT, which process text bidirectionally, GPT processes text in a **unidirectional** manner (left-to-right).\n",
    "- The model is trained in an **autoregressive** manner, meaning that it generates the next word in a sequence based on the previously generated words. This allows GPT to generate fluent and coherent text, word by word.\n",
    "- GPT uses a **causal self-attention** mechanism, which helps the model focus on the relevant context from the previous words when predicting the next word in the sequence.\n",
    "\n",
    "![\"gpt\"](../images/4/4-gpt.png)\n",
    "\n",
    "#### GPT Features\n",
    "\n",
    "- **Autoregressive Generation**: GPT generates text by predicting the next word based on the preceding context. This allows it to produce human-like and coherent text when given a prompt.\n",
    "- **Large-scale Pretraining**: GPT models are pretrained on massive text datasets, enabling them to learn a wide range of linguistic patterns and knowledge. This pretraining makes GPT highly versatile and capable of performing well across various NLP tasks.\n",
    "- **Fine-tuning**: After pretraining, GPT can be fine-tuned on specific tasks or domains to improve its performance on specialized tasks such as question answering, summarization, or translation.\n",
    "- **Text Completion and Dialogue Systems**: GPT excels at tasks like text completion and conversation generation, making it suitable for applications like chatbots, content creation, and automated writing assistants.\n",
    "\n",
    "GPT has become one of the most widely used models in the NLP community due to its impressive text generation abilities and versatility in various tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321a9b8b36904364b6c8a03ded1e71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d75975ceba42c5bb8762efcb28f308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a920a62d6454a539e7d84fe4a3b4b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f26544f52874125aa757164a7428be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c9c5f76d9745d58b248ac2f8786516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea86b0308874191863209e3d233dd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463d12f5866a49159df900da2c30d22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b46faaead54ee1901f19b61b138f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78f1fb0ca4b4347bd3c03c31480067e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model and Tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name, force_download=True\n",
    ")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name, force_download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pad_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"I go to swim for\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention mask\n",
    "attention_mask = inputs.ne(tokenizer.pad_token_id).to(inputs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Create text\n",
    "output = model.generate(inputs, max_length=20, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I go to swim for a while, and I'm not sure if I'm going to be able\n"
     ]
    }
   ],
   "source": [
    "# Decode the result\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
