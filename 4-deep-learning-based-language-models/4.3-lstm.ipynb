{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM (Long Short-Term Memory)\n",
    "\n",
    "#### What is LSTM?\n",
    "\n",
    "LSTM (Long Short-Term Memory) is a type of Recurrent Neural Network (RNN) designed to handle the vanishing gradient problem. It was developed to learn and remember long-term dependencies in sequential data. Unlike standard RNNs, LSTMs have a more complex architecture that allows them to better capture long-range dependencies.\n",
    "\n",
    "![\"lstm\"](../images/4/4-lstm.png)\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "#### LSTM's Improvement Over RNN\n",
    "\n",
    "RNNs suffer from a problem called the vanishing gradient problem, where gradients diminish as they are backpropagated through time, making it difficult for the network to learn long-term dependencies. LSTMs improve upon RNNs by introducing memory cells that allow them to retain information over long periods, which helps to address the vanishing gradient problem.\n",
    "\n",
    "#### LSTM Architecture, Components, and Working\n",
    "\n",
    "LSTM has three main components:\n",
    "\n",
    "1. **Forget Gate**: Decides what information from the cell state should be discarded.\n",
    "2. **Input Gate**: Determines what new information should be added to the cell state.\n",
    "3. **Output Gate**: Decides what part of the cell state should be output to the next hidden state.\n",
    "\n",
    "The working of LSTM can be broken down as follows:\n",
    "\n",
    "- **Forget Gate**: It takes the previous hidden state and the current input, applies a sigmoid activation to decide which parts of the previous memory should be discarded.\n",
    "- **Input Gate**: It adds new information to the cell state using a tanh activation function to create candidate values that could be added to the memory.\n",
    "- **Cell State Update**: The cell state is updated by combining the forget gate’s output and the input gate’s output.\n",
    "- **Output Gate**: The final output is based on the cell state, which is passed through the output gate and used in the next hidden state.\n",
    "\n",
    "#### Applications of LSTM\n",
    "\n",
    "LSTMs are commonly used in tasks that involve sequential data, such as:\n",
    "\n",
    "- **Natural Language Processing (NLP)**: Sentiment analysis, text generation, machine translation.\n",
    "- **Speech Recognition**: Converting spoken language into text.\n",
    "- **Time Series Prediction**: Forecasting stock prices, weather predictions.\n",
    "- **Video Processing**: Action recognition, object tracking.\n",
    "\n",
    "#### RNN vs LSTM (Graphical Comparison)\n",
    "\n",
    "Here is a graphical comparison of RNN and LSTM:\n",
    "\n",
    "![rnn-vs-lstm](../images/4/4-rnn-vs-lstm.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real-Life Application of RNN Using the Daily Dialog Dataset\n",
    "\n",
    "- The dataset link &rarr; [Daily_Dialog_Dataset.csv](https://www.kaggle.com/datasets/va6573/daily-dialog-clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion                                               Text\n",
      "0      joy          yes now i have got it thank you very much\n",
      "1  neutral  if i do a few exercises at home like crunches ...\n",
      "2  neutral  ok i hope you can have these goods delivered b...\n",
      "3  neutral                            well she is quite short\n",
      "4      joy    oh thank you i am looking for the train station\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv(\"../data/Daily_Dialog_Dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "texts = df[\"Text\"].astype(str).tolist()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing tokenizer and sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text sorting and padding\n",
    "input_sequences = []\n",
    "for text in texts:\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[: i + 1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_length = max(len(x) for x in input_sequences)\n",
    "input_sequences = pad_sequences(\n",
    "    input_sequences, maxlen=max_sequence_length, padding=\"pre\"\n",
    ")\n",
    "\n",
    "X, Y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "Y = tf.keras.utils.to_categorical(Y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 50))\n",
    "model.add(LSTM(200, return_sequences=False))\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.2693 - loss: 3.5756\n",
      "Epoch 2/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 78ms/step - accuracy: 0.2947 - loss: 3.3791\n",
      "Epoch 3/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 77ms/step - accuracy: 0.3222 - loss: 3.2243\n",
      "Epoch 4/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 77ms/step - accuracy: 0.3484 - loss: 3.0661\n",
      "Epoch 5/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - accuracy: 0.3856 - loss: 2.8821\n",
      "Epoch 6/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.4123 - loss: 2.7295\n",
      "Epoch 7/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - accuracy: 0.4419 - loss: 2.5897\n",
      "Epoch 8/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.4724 - loss: 2.4587\n",
      "Epoch 9/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - accuracy: 0.4996 - loss: 2.3192\n",
      "Epoch 10/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - accuracy: 0.5146 - loss: 2.2118\n",
      "Epoch 11/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.5441 - loss: 2.0874\n",
      "Epoch 12/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 92ms/step - accuracy: 0.5705 - loss: 1.9799\n",
      "Epoch 13/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.5886 - loss: 1.8869\n",
      "Epoch 14/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - accuracy: 0.6202 - loss: 1.7623\n",
      "Epoch 15/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - accuracy: 0.6415 - loss: 1.6657\n",
      "Epoch 16/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.6574 - loss: 1.5889\n",
      "Epoch 17/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.6793 - loss: 1.5010\n",
      "Epoch 18/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 78ms/step - accuracy: 0.6901 - loss: 1.4416\n",
      "Epoch 19/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - accuracy: 0.7159 - loss: 1.3383\n",
      "Epoch 20/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.7304 - loss: 1.2807\n",
      "Epoch 21/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.7450 - loss: 1.2194\n",
      "Epoch 22/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - accuracy: 0.7500 - loss: 1.1823\n",
      "Epoch 23/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.7682 - loss: 1.0971\n",
      "Epoch 24/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.7742 - loss: 1.0827\n",
      "Epoch 25/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.7861 - loss: 1.0108\n",
      "Epoch 26/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - accuracy: 0.7968 - loss: 0.9512\n",
      "Epoch 27/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.8071 - loss: 0.9118\n",
      "Epoch 28/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - accuracy: 0.8151 - loss: 0.8795\n",
      "Epoch 29/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - accuracy: 0.8203 - loss: 0.8363\n",
      "Epoch 30/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8248 - loss: 0.8090\n",
      "Epoch 31/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.8317 - loss: 0.7801\n",
      "Epoch 32/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8405 - loss: 0.7426\n",
      "Epoch 33/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - accuracy: 0.8440 - loss: 0.7197\n",
      "Epoch 34/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8492 - loss: 0.6915\n",
      "Epoch 35/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8532 - loss: 0.6728\n",
      "Epoch 36/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 79ms/step - accuracy: 0.8578 - loss: 0.6432\n",
      "Epoch 37/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8634 - loss: 0.6168\n",
      "Epoch 38/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8649 - loss: 0.6019\n",
      "Epoch 39/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8707 - loss: 0.5681\n",
      "Epoch 40/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - accuracy: 0.8726 - loss: 0.5545\n",
      "Epoch 41/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8766 - loss: 0.5473\n",
      "Epoch 42/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - accuracy: 0.8734 - loss: 0.5324\n",
      "Epoch 43/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.8786 - loss: 0.5113\n",
      "Epoch 44/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8732 - loss: 0.5212\n",
      "Epoch 45/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 79ms/step - accuracy: 0.8733 - loss: 0.5087\n",
      "Epoch 46/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8818 - loss: 0.4826\n",
      "Epoch 47/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8787 - loss: 0.4817\n",
      "Epoch 48/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8834 - loss: 0.4735\n",
      "Epoch 49/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - accuracy: 0.8800 - loss: 0.4624\n",
      "Epoch 50/50\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.8831 - loss: 0.4544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21eb8a18f50>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Text completion task\n",
    "def predict_next_word(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_sequence_length - 1, padding=\"pre\"\n",
    "        )\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        predicted_word_index = np.argmax(predicted_probs, axis=-1)\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
    "\n",
    "        seed_text += \" \" + predicted_word\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"this\"\n",
    "print(predict_next_word(seed_text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a good thing\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"it is\"\n",
    "print(predict_next_word(seed_text, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did you work as a salesperson before\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"did you\"\n",
    "print(predict_next_word(seed_text, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
